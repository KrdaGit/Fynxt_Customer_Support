{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681bd858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71608c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Fyxt_CS\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Initialize Chroma and embedding\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection_name = \"Fynxt_database\"\n",
    "\n",
    "# Check if collection exists or create new\n",
    "try:\n",
    "    chroma_collection = chroma_client.get_collection(collection_name, embedding_function=embedding_function)\n",
    "except:\n",
    "    chroma_collection = chroma_client.create_collection(collection_name, embedding_function=embedding_function)\n",
    "\n",
    "# Text wrapping utility (optional for CLI)\n",
    "def word_wrap(text, width=100):\n",
    "    import textwrap\n",
    "    return \"\\n\".join(textwrap.wrap(text, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd58d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Knowledgebase built with 8 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Build knowledgebase (run once or if PDFs are updated)\n",
    "def build_pdf_knowledgebase(pdf_paths: List[str]):\n",
    "    all_text = []\n",
    "\n",
    "    for path in pdf_paths:\n",
    "        reader = PdfReader(path)\n",
    "        text_content = [p.extract_text().strip() for p in reader.pages if p.extract_text()]\n",
    "        all_text.extend(text_content)\n",
    "\n",
    "    combined_text = '\\n\\n'.join(all_text)\n",
    "\n",
    "    # Step 1: Character-level splitting\n",
    "    character_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=2000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    character_chunks = character_splitter.split_text(combined_text)\n",
    "\n",
    "    # Step 2: Token-level splitting\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(tokens_per_chunk=256, chunk_overlap=20)\n",
    "    token_chunks = []\n",
    "    for text in character_chunks:\n",
    "        token_chunks += token_splitter.split_text(text)\n",
    "\n",
    "    # Filter short/empty chunks\n",
    "    token_chunks = [chunk for chunk in token_chunks if len(chunk.strip()) > 30]\n",
    "\n",
    "    # Store in ChromaDB\n",
    "    ids = [str(i) for i in range(len(token_chunks))]\n",
    "    metadatas = [{\"source\": f\"{os.path.basename(path)}_chunk_{i}\"} for i in range(len(token_chunks))]\n",
    "    chroma_collection.add(ids=ids, documents=token_chunks, metadatas=metadatas)\n",
    "\n",
    "    print(f\"✅ Knowledgebase built with {len(token_chunks)} chunks.\")\n",
    "\n",
    "# Run once to build\n",
    "build_pdf_knowledgebase([\"G:/Fyxt_CS/Docs/Final_Doc.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9c901ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage\n",
    "import random\n",
    "\n",
    "# Query function\n",
    "@tool\n",
    "def query_pdf_knowledgebase(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Answers a user's query based on pre-loaded documentation in ChromaDB.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "    retrieved_documents = results['documents'][0]\n",
    "\n",
    "    if not retrieved_documents:\n",
    "        return \"⚠️ No relevant information found.\"\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.strip() for doc in retrieved_documents])\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a helpful customer support assistant. Your users are asking questions about specific feature of the financial software.\"\n",
    "        \"Use only the provided content to answer accurately.\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        f\"Information:\\n{context}\"\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Updated ticket generation tool\n",
    "@tool\n",
    "def generate_support_ticket(chat_history: list[BaseMessage]) -> str:\n",
    "    \"\"\"\n",
    "    Generates a support ticket when no relevant documentation is found.\n",
    "    Summarizes the conversation to create the ticket.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "    full_convo = \"\\n\".join(\n",
    "        f\"{msg.type.capitalize()}: {msg.content}\" for msg in chat_history\n",
    "    )\n",
    "\n",
    "    summary_prompt = (\n",
    "        \"You are a support assistant. Summarize the user's issue clearly and concisely \"\n",
    "        \"based on the following conversation:\\n\\n\"\n",
    "        f\"{full_convo}\\n\\n\"\n",
    "        \"Only summarize the issue (do not include greetings or confirmations).\"\n",
    "    )\n",
    "\n",
    "    summary = model.generate_content(summary_prompt).text.strip()\n",
    "\n",
    "    ticket_id = f\"TICKET-{random.randint(1000, 9999)}\"\n",
    "    return (\n",
    "        f\"✅ Ticket created!\\n\\n\"\n",
    "        f\"📄 **Ticket ID**: {ticket_id}\\n\"\n",
    "        f\"📝 **Issue**: {summary}\\n\"\n",
    "        f\"A customer support rep will follow up with you soon.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "971d9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from typing import List\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "tools = [query_pdf_knowledgebase, generate_support_ticket]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f204a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Any, Optional\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    memory: ConversationBufferMemory\n",
    "\n",
    "# AgentState\n",
    "def assistant(state: AgentState) -> AgentState:\n",
    "    messages = state[\"messages\"]\n",
    "    memory = state[\"memory\"]\n",
    "\n",
    "    # Retrieve past conversation from memory (if available)\n",
    "    history = []\n",
    "    if memory:\n",
    "        history = memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "        if isinstance(history, str):\n",
    "            history = []  # fallback if memory is still warming up\n",
    "\n",
    "    # Updated system prompt\n",
    "    system_prompt = SystemMessage(content=(\n",
    "    \"You are a helpful customer support assistant. \"\n",
    "    \"Always use the `query_pdf_knowledgebase` tool first to answer the user's question, \"\n",
    "    \"based on the product documentation. \"\n",
    "    \"If the tool returns 'No relevant information found', ask the user if they want to raise a ticket. \"\n",
    "    \"If they say yes, call the `generate_support_ticket` tool with the full chat history. \"\n",
    "    \"Never skip using the `query_pdf_knowledgebase` tool.\"\n",
    "))\n",
    "\n",
    "    full_messages = [system_prompt] + history + messages\n",
    "\n",
    "    # Run the model with tools\n",
    "    response = llm_with_tools.invoke(full_messages)\n",
    "\n",
    "    # Save to memory\n",
    "    if memory:\n",
    "        memory.save_context({\"input\": messages[-1].content}, {\"output\": response.content})\n",
    "\n",
    "    return {\n",
    "        \"messages\": messages + [response],\n",
    "        \"memory\": memory,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e66a234c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile(name=\"CustomerSupportAgent\")\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c234138c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I cannot find the answer to your question in the documentation. Would you like me to raise a support ticket for you?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import messages_from_dict\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True,memory_key=\"history\")\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"How can I enable or disable fee structures for PAMM?\")],\n",
    "    \"memory\": memory,\n",
    "}\n",
    "\n",
    "final_state = react_graph.invoke(initial_state)\n",
    "final_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc6b5c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}, id='e5b389fa-0a05-4feb-8206-0e23debe7164'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'query_pdf_knowledgebase', 'arguments': '{\"query\": \"enable or disable fee structures for PAMM\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-81c0eddb-864d-419d-a8e4-d3cef9d32d4e-0', tool_calls=[{'name': 'query_pdf_knowledgebase', 'args': {'query': 'enable or disable fee structures for PAMM'}, 'id': '3ed03a70-89e0-4a60-a84d-cf94f5268f3a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 15, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", name='query_pdf_knowledgebase', id='34391b46-ef0d-491b-99f1-12fe88ceeeec', tool_call_id='3ed03a70-89e0-4a60-a84d-cf94f5268f3a', status='error'),\n",
       "  AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e5555b94-763e-4538-8d50-bc74f8caacf4-0', usage_metadata={'input_tokens': 231, 'output_tokens': 29, 'total_tokens': 260, 'input_token_details': {'cache_read': 0}})],\n",
       " 'memory': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}), AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={})]), return_messages=True)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9963bc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I want to setup account for my MT4, how to do that?\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92ed672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I want to setup account for my MT4, how to do that?', additional_kwargs={}, response_metadata={}, id='6ef45663-c5ee-40b6-97ec-242197a2928b'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'query_pdf_knowledgebase', 'arguments': '{\"query\": \"setup account for MT4\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-54088564-e03e-4b51-a828-5e634d181e4f-0', tool_calls=[{'name': 'query_pdf_knowledgebase', 'args': {'query': 'setup account for MT4'}, 'id': 'd74afb04-89e0-499f-a63a-d14c66f1e624', 'type': 'tool_call'}], usage_metadata={'input_tokens': 157, 'output_tokens': 12, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", name='query_pdf_knowledgebase', id='7f51e537-df86-49ae-9af9-9d554be3ac3d', tool_call_id='d74afb04-89e0-499f-a63a-d14c66f1e624', status='error'),\n",
       "  AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-78b87340-f10b-40b9-8323-4ac3f8f82dbf-0', usage_metadata={'input_tokens': 231, 'output_tokens': 30, 'total_tokens': 261, 'input_token_details': {'cache_read': 0}})],\n",
       " 'memory': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}), AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='I want to setup account for my MT4, how to do that?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}), AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?', additional_kwargs={}, response_metadata={})]), return_messages=True)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b0573fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you please provide the original question, so I can generate the support ticket?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Yes, please generate the ticket\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b66efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Yes, please generate the ticket', additional_kwargs={}, response_metadata={}, id='e1a1bfc9-a98b-43af-8c01-ef79ef7ec3f8'),\n",
       "  AIMessage(content='Can you please provide the original question, so I can generate the support ticket?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-315492d0-8274-4ec2-82aa-1763d043e643-0', usage_metadata={'input_tokens': 148, 'output_tokens': 17, 'total_tokens': 165, 'input_token_details': {'cache_read': 0}})],\n",
       " 'memory': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}), AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='I want to setup account for my MT4, how to do that?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}), AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Yes, please generate the ticket', additional_kwargs={}, response_metadata={}), AIMessage(content='Can you please provide the original question, so I can generate the support ticket?', additional_kwargs={}, response_metadata={})]), return_messages=True)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e65f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I want to setup account for my MT4, how to do that?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, please generate the ticket', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Can you please provide the original question, so I can generate the support ticket?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state[\"memory\"].chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "304bca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay Krunal, how can I help you today?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"my name is krunal\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2c0c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, I cannot help you with that request. I can only answer questions based on the pre-loaded documentation. Would you like to raise a ticket?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I live in surat\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9996f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have enough information to answer your question. Would you like me to create a support ticket?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Im from india and its summar going on here\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e0c90d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do not have access to your personal information, so I don't know your name.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state = react_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Do know my name?\")],\n",
    "    \"memory\": final_state[\"memory\"],\n",
    "})\n",
    "next_state[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1371a7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='How can I enable or disable fee structures for PAMM?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to create a support ticket for you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I want to setup account for my MT4, how to do that?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Error: ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.')\\n Please fix your mistakes.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am sorry, I cannot find the answer to your question in the knowledge base. Would you like me to raise a support ticket for you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, please generate the ticket', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Can you please provide the original question, so I can generate the support ticket?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='my name is krunal', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Okay Krunal, how can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I live in surat', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I am sorry, I cannot help you with that request. I can only answer questions based on the pre-loaded documentation. Would you like to raise a ticket?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Im from india and its summar going on here', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I don't have enough information to answer your question. Would you like me to create a support ticket?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Do know my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I do not have access to your personal information, so I don't know your name.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state[\"memory\"].chat_memory.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
